library(dplyr)
#체중데이터 가져오기
data <- NHIS_OPEN_GJ_2015 %>%
+ select('신장(5cm단위)','체중(5kg 단위)')
NHIS_OPEN_GJ_2015 <- read_csv("D:/R/NHIS_OPEN_GJ_2015.CSV",
locale=locale(encoding="euc-kr"))
#요약통계
library(readr)
NHIS_OPEN_GJ_2015 <- read_csv("D:/R/NHIS_OPEN_GJ_2015.CSV",
locale=locale(encoding="euc-kr"))
#체중데이터 가져오기
data <- NHIS_OPEN_GJ_2015 %>%
+ select('신장(5cm단위)','체중(5kg 단위)')
#체중데이터 가져오기
data <- NHIS_OPEN_GJ_2015 %>%
select('신장(5cm단위)','체중(5kg 단위)')
View(NHIS_OPEN_GJ_2015)
#체중데이터 가져오기
data <- NHIS_OPEN_GJ_2015 %>%
select('신장(5Cm단위)','체중(5kg 단위)')
#체중데이터 가져오기
data <- NHIS_OPEN_GJ_2015 %>%
select('신장(5Cm단위)','체중(5Kg 단위)')
head(data)
cor(data, method = "pearson")
cor(data$`신장(5Cm단위)`,data$`체중(5Kg 단위)`,method="pearson")
cor.test(data$`신장(5Cm단위)`,data$`체중(5Kg 단위)`)
#회귀분석
data2 <- NHIS_OPEN_GJ_2015 %>%
select('체중(5Kg 단위)',허리둘레,'신장(5Cm단위)')
set.seed(123)
idx <- sample(2,size=NROW(data2),replace=T,prob=c(0.7,0.3))
train_data <- data[idx==1,]
test_data <- data2[idx==2,]
train_data <- data[idx==1,]
train_data <- data2[idx==1,]
train_result <- lm('체중(5Kg 단위)'~허리둘레+'신장(5Cm단위)',data=train_data)
summary(train_result)
train_result <- lm('체중(5Kg 단위)'~허리둘레+'신장(5Cm단위)',data=train_data)
train_result <- lm('체중(5Kg 단위)'~허리둘레+'신장(5Cm단위)',data=train_data)
train_result <- lm('체중(5Kg 단위)' ~ 허리둘레 + '신장(5Cm단위)',data=train_data)
View(train_data)
idx
View(data2)
train_result <- lm('체중(5Kg 단위)' ~ 허리둘레,data=train_data)
train_result <- lm('체중(5Kg 단위)' ~ '신장(5Cm단위)',data=train_data)
train_result <- lm('체중(5Kg 단위)'~ '신장(5Cm단위)',data=train_data)
train_result <- lm('체중(5Kg 단위)'~ '신장(5Cm단위)',data='train_data')
idx==1
train_result <- lm('체중(5Kg 단위)'~ 허리둘레 + '신장(5Cm단위)',data=train_data)
is.numeric('체중(5Kg 단위)')
is.numeric(허리둘레)
is.numeric(허리둘레,data=train_data)
is.numeric('허리둘레',data=train_data)
is.numeric(train_data$허리둘레)
is.numeric(train_data$`신장(5Cm단위)`)
is.numeric(train_data$`체중(5Kg 단위)`)
train_result <- lm('체중(5Kg 단위)'~ 허리둘레 + '신장(5Cm단위)',data=data2)
train_result <- lm('체중(5Kg 단위)'~ 허리둘레 + '신장(5Cm단위)',data=train_data)
train_result <- lm('체중(5Kg 단위)'~ '허리둘레' + '신장(5Cm단위)',data=train_data)
train_data<- data2[idx==1,]
train_result <- lm('체중(5Kg 단위)'~ 허리둘레 + '신장(5Cm단위)',data=train_data)
nrow(train_data)
train_result <- lm([,1]~ [,2] + [,3],data=train_data)
train_result <- lm(train_data[,1]~ train_data[,2] + train_data[,3])
train_result <- lm(train_data$`체중(5Kg 단위)`~ train_data$허리둘레 + train_data$`신장(5Cm단위)`)
summary(train_result)
y <- c(1,2,3,4)
x = 2
x
y <- c(1,2,3,4)
y
y + x
y/x
y*y
y%*%y
x1 <- seq(5)
x2 <- seq(1,5)
x3 <- seq(from=1, to=5, by=1)
x4 <- seq(1,5,1)
x5 <- seq(1,5,length=5)
x1;x2;x3;x4;x5
rep(1,5)
rep(c(1,2), 3)
AB <- c("A", "B")
rep(AB, 3)
rep(AB, times=c(4,2))
x= 1:4
x[1]
x[1:3]
x[-4]
x[c(T,T,F,F)]
x<- c("low","med","high","med","high")
xf <- factor(x)
xf
as.numeric(xf)
xf2 <- factor(x, levels = c("low","med","high"))
xf2
as.numeric(xf2)
xf
xf[3] = "Extreme"
xf
xf[3] = "low"
xf
levels(xf)
levels(xf)[1] <- "Extreme"
xf
A1 <- matrix(1:9, nrow=3, ncol=3)
A1
A2 <- matrix(1:9, 3, 3, byrow=T)
A2
t(A1)
A1+A2
eng <- c(60,72,57,90,95,72)
math <- c(75,80,92,91,87,50)
score1 <- cbind(eng, math)
score1
score2 <- rbind(eng,math);score2
A <- matrix(1,3,3);A
I = diag(3)
B = 0.3*A + 0.7*I;B
solve(B)
solve(B) %*% B
C <- array(1:24, dim=c(3,4,2))
C
C[2,3,1]
C[,2,1]
data(iris)
head(iris)
dim(iris)
names(iris)
iris[1,]
mylist = list(Math=math, Eng=eng, Name="final")
mylist
mylist$Math; mylist[[1]]
mylist$Math[2]; mylist[[1]][2]
mylist2 = list(a=1:3,b=matrix(1:4,2,2),c="example")
mylist2
x <- (1:10)*10; x
length(x)
mean(x); sum(x)
var(x); sd(x)
min(x); max(x)
quantile(x, probs = c(0.25,0.75))
summary(x)
set.seed(10)
x = rnorm(n=500,mean=0,sd=1)
plot(x)
hist(x); abline(v=0, col="red")
a=factor(c("a","b","c","b","c","a","c","c","a"))
plot(a)
hist(iris$Sepal.Length,xlab="cm")
hist(iris$Sepal.Length,breaks = 20,xlab="cm")
plot(iris$Sepal.L, iris$Petal.Width,
xlab=c("Sepal Length (cm)"),ylab=c("Petal Width (cm)"))
plot(iris[,1:4], main="Scatter Plots for Iris Variable",pch=16)
myfun <- function(n, mu, Sigma=diag(length(mu))){
P = length(mu)  #차원
R = chol(Sigma)  #Cholesky decomposition of Sigma
#Sigma = t(R) %*% R
z = matrix(rnorm(n*p),n ,p)
res = z %*% R + matrix(mu, n, p, byrow=T)
return(res)
}
myfun <- function(n, mu, Sigma=diag(length(mu))){
p = length(mu)  #차원
R = chol(Sigma)  #Cholesky decomposition of Sigma
#Sigma = t(R) %*% R
z = matrix(rnorm(n*p),n ,p)
res = z %*% R + matrix(mu, n, p, byrow=T)
return(res)
}
myfun(3, mu=1:2)
for (i in 1:5){
print(i)
}
x=0
for(j in 1:10){
x = x + j
}
x
vec = rep(NaN, 10); vec
s=0
for(i in 1:10){
s = s+i
vec[i] = s;
}
c(1+2, vec[2])
c(1+2+3+4+5+6, vec[6])
set.seed(1)
rm(list=ls())
n=10
mu=4
sigma=10
y <- rnorm(n, mean=mu, sd=sigma)
y
set.seed(1)
y <- rnorm(n, mean=mu, sd = sigma)
y
ybar <- mean(y)
s2 <- var(y)
c(ybar, s2)
c(mu,sigma)
nrep = 10000
s2 <- rep(NaN, nrep)
for (i in 1:nrep){
y=rnorm(n, mean = mu, sd=sigma)
ybar[i] = mean(y)
s2[i] = var(y)
}
cbind(c(mean(ybar),mean(s2)),c(mu,sigma^2))
#표본수를 늘리니 평균과 분산이 모평균,모분산과 비슷
cbind(c(mean(ybar)-mu, mean(s2)-sigma^2))
n=1000
for(i in 1:nrep){
y = rnorm(n, mean=mu, sd=sigma)
ybar[i] = mean(y)
s2[i] = var(y)
}
cbind(c(mean(ybar)-mu, mean(s2)-sigma^2))
data(cars)
head(cars)
X = cars$speed
Y = cars$dist
plot(X,Y)
n = length(Y)
mean_x = mean(X);
mean_Y = mean(Y)
var_x = var(X);
var_Y = var(Y)
cov_xy = cov(X,Y)
SS_xx <- (n-1)*var_x
SS_xy <- (n-1)*cov_xy
SS_yy <- (n-1)*var_Y
b1 <- SS_xy/SS_xx
b0 <- mean_y - b1*mean_x
b0 <- mean_Y - b1*mean_x
yhat <- b0 + b1*X
e <- Y-yhat
SSE <- sum(e^2)
MSE <- SSE/(n-2)
s <- sqrt(MSE)
print(cbind(mean_x,mean_Y))
print(cbind(SS_xx, SS_xy, SS_yy))
print(cbind(b0,b1))
print(cbind(Y,yhat,e))
plot(X,Y,xlim = c(0,125))
abline(a=b0, b=b1, col='red')
plot(e)
mod <- lm(Y~X)
plot(X,Y,xlim = c(0,125))
abline(mod)
abline(a=b0, b=b1, col='red')
cbind(c(b0,b1),mod$coefficients)
cbind(s, summary(mod)$sigma)
cbind(yhat, mod$fitted)
Nsim=100
N=101
beta0=1
beta1=3
X = seq(0,1,1/(N-1))
sigma=2
Y = matrix(rep(N*Nsim),nrow=N, ncol=Nsim)
sigma_matrix = matrix(rep(Nsim),nrow=1,ncol=Nsim)
coeff_matrix = matrix(rep(2*Nsim),nrow=2,ncol=Nsim)
for(i in 1:Nsim){
epsilon = rnorm(N, mean=0, sd=sigma)
Y[,i]=beta0 + beta1*X + epsilon
mod = lm(Y[,i]~X)
coeff_matrix[,i] = mod$coefficients
sigma_matrix[i]=summary(mod)$sigma
}
apply(coeff_matrix, 1, mean)
bias_b = apply(coeff_matrix, 1, mean)-c(beta0,beta1)
bias_s = mean(sigma_matrix)-sigma
c(bias_b, bias_s)
hist(coeff_matrix[1,],main=c("Histogram of b0"),
braks=20, xlab="b0")
hist(coeff_matrix[1,],main=c("Histogram of b0"),
breaks=20, xlab="b0")
hist(sigma_matrix, main=c("Histogram of sigmahat"),
breaks=20, xlab="b1")
Nsim=10000
Y=matrix(rep(N*Nsim),nrow=N,ncol=Nsim)
coeff_matrix = matrix(rep(2*Nsim),nrow=2,ncol=Nsim)
sigma_matrix = matrix(rep(Nsim),nrow=1,ncol=Nsim)
epsilon = rnorm(N, mean=0, sd=sigma)
for(i in 1:Nsim){
epsilon = rnorm(N, mean=0, sd=sigma)
Y[,i]=beta0 + beta1*X + epsilon
mod = lm(Y[,i]~X)
coeff_matrix[,i] = mod$coefficients
sigma_matrix[i] = summary(mod)$sigma
}
bias_b_large = apply(coeff_matrix, 1, mean)-c(beta0,beta1)
bias_s_large = mean(sigma_matrix)-sigma
c(bias_b_large, bias_s_large)
cbind(bias_b,bias_b_large)
cbind(bias_s,bias_s_large)
#Likelihood Principle
theta <- seq(0,1,length=1000)
ltheta <- choose(10,3)*theta^3*(1-theta)^7
plot(theta, ltheta, type = "l",main="Likelihood Function",
ylab = "Likelihood L(theta|X)")
abline(v=0.3,lty=2,col=2)
#Quantile-based Interval
theta = seq(-3,3,length=500)
plot(theta,dnorm(theta, 0.3, 0.5),type="l",ylab="density")
abline(v=qnorm(c(0.049,0.999),0.3,0.5),lty=2, col=2)
abline(v=qnorm(c(0.025,0.975),0.3,0.5),lty=1,col=4)
#Quantile-based Method
n=100
x1 <- rnorm(n,0,1)
quantile(x1, c(.025,.975))
n2 <- 1000
x2 <- rnorm(n2,0,1)
quantile(x2, c(.025,.975))
par(mfrow=c(1,2))
hist(x1);hist(x2)
#HPD Method2 : Grid Search Method(격자점방법)
HPDgrid <- function(prob, level=.95){
prob.sort = sort(prob, decreasing = T)
M = min(which(cumsum(prob.sort)>=level))
height = prob.sort[M]
HPD.index = which(prob >= height)
HPD.level = sum(prob[HPD.index])
res = list(index = HPD.index, level = HPD.level)
return(res)
}
N = 1001
theta = seq(-3,3,length = N)
prob = exp(-0.5/0.25*(theta-0.3)^2)
prob = prob/sum(prob)
alpha = 0.05;level = 1-alpha
HPD = HPDgrid(prob, level)
HPDgrid.hat = c(min(theta[HPD$index]))
max(theta[HPD$index])
HPDgrid.hat
HPDgrid.hat = c(min(theta[HPD$index]),max(theta[HPD$index])
)
HPDgrid.hat = c(min(theta[HPD$index]),max(theta[HPD$index]))
HPDgrid.hat
x1 <- rep(c(0,1,2,3,4,5,6),c(7,14,13,8,4,2,2))
a = 2; b = 1
n1 <- length(x1); s1 <- sum(x1)
n2 <- length(x2); s2 <- sum(x2)
postmean.theta1 = (a+s1)/(b+n1)
postmean.theta2 = (a+s2)/(b+s2)
###plot the posterior
par(mfrow = c(1,1))
theta <- seq(0, 6, length=100)
plot(theta, dgamma(theta, a+s1, b+n1), type="l",
xlab="theta",ylab="p(theta|x")
lines(theta,dgamma(theta, a+s2,b+n2),lty=2,col="red")
lines(theta, dgamma(theta,a,b),lty=3,col="blue")
legend(2.5,1.5,legend=c(paste("City 1"),paste("City2"),
paste("Gamma(2,1) prior")),
cex=1.3,lty=c(1,2,3),col=c(1,2,4),bty="n")
lines(theta,dgamma(theta, a+s2,b+n2),lty=2,col="red")
postmean.theta2 = (a+s2)/(b+n2)
lines(theta, dgamma(theta,a,b),lty=3,col="blue")
###plot the posterior
par(mfrow = c(1,1))
theta <- seq(0, 6, length=100)
plot(theta, dgamma(theta, a+s1, b+n1), type="l",
xlab="theta",ylab="p(theta|x")
lines(theta,dgamma(theta, a+s2,b+n2),lty=2,col="red")
lines(theta, dgamma(theta,a,b),lty=3,col="blue")
##Ch6
#predictive distribution of x_{n+1}
x1 <- c(rep(0,7),rep(1,14),rep(2,13),rep(3,8),rep(4,4),
rep(5,2),rep(6,2))
x2 <- c(rep(0,4),rep(1,13),rep(2,15),rep(3,6),
rep(4,2),rep(5,2),rep(6,3),rep(7,1))
a=2;b=1
n1 = length(x1);s1 = sum(x1)
n2 = length(x2);s2 = sum(x2)
x = seq(0,10)
par(mfrow=c(1,2))
plot(x,dnbinom(x,size=a+s1,prob=(b+n1)/(b+n1+1)),
xlab = "x_{n+1}",ylab = "Predictive Prob",
type="h",main="City1")
plot(x,dnbinom(x,size=a+s2,prob=(b+s2)/(b+n2+1)),
xlab="x_{n+1}",ylab="Predictive Prob",type="h",
main="City2")
plot(x,dnbinom(x,size=a+s2,prob=(b+n2)/(b+n2+1)),
xlab="x_{n+1}",ylab="Predictive Prob",type="h",
main="City2")
par(mfrow=c(1,2))
plot(x,dnbinom(x,size=a+s1,prob=(b+n1)/(b+n1+1)),
xlab = "x_{n+1}",ylab = "Predictive Prob",
type="h",main="City1")
plot(x,dnbinom(x,size=a+s2,prob=(b+n2)/(b+n2+1)),
xlab="x_{n+1}",ylab="Predictive Prob",type="h",
main="City2")
